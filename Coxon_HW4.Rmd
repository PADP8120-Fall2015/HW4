
---
title: "Coxon_PADP8120_Homework4"
author: "Fall 2015"
date: "![Creative Commons Attribution License](images/cc-by.png)"
output:
  html_document:
    highlight: pygments
    theme: cerulean
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
---


# Homework 4

Guidelines: Homeworks should be clear and legible, with answers clearly indicated and work shown. Homeworks will be given a minus, check, or check plus owing to completion and correctness. You are welcome to work with others but please submit your own work. Your homework must be produced in an R Markdown (.rmd) file submitted via github. If you are having trouble accomplishing this, please refer to the [guide](http://spia.uga.edu/faculty_pages/tyler.scott/teaching/PADP8120_Fall2015/Homeworks/submitting_homework.shtml). 


This homework adapts materials from the work of Michael Lynch (http://spia.uga.edu/faculty_pages/mlynch/) and Matthew Salganik (http://www.princeton.edu/~mjs3/)

## Topics

Topics covered in this homework include:

- Bivariate and multivariate regression
- Regression diagnostics

## Problems

### Problem 1. 

Write a function that emulates the `lm` function in R for a simple (bivariate) regression. Like the `lm` function, your function should be able to estimate and report to the screen `B_k` coefficients, standard errors for these coefficients, and corresponding t-values and p-values. It should also report the residual standard error and $R^2$. Be sure to show your code. Compare your results to the results of the `lm` function on some data of your choosing to verify that things are working correctly. 

###### Formulas
$E(Y|x)$ = $\beta_0 + \beta_1$*x_i    
$\beta_1$ = $\sum_{i=1}^n$ $(x_i - \bar{x})$*$(y_i - \bar{y})$ / $(x_i - \bar{x})^2$
$\beta_0$ = $\bar{y}$ - $\beta_1$*$x_i$
Best estimate of $\sigma^2$ is $s^2$ = $\sum_{i=1}^n$ $(y_i - \bar{y})^2$ / $n-2$

```{r}
x = rnorm(100)
y = rnorm(100)

victoria.lm = function(y,x)
{
  b1 = round({sum(x * y) - (1/length(y)) * sum(y)} / {sum(x^2) - (1/length(y)) * sum(x)^2}, 5)
  b0 = round(mean(y) - b1 * mean(x),5)
  SEr = sqrt(sum({(y - (b0 + b1 * x))^2}) /
(length(y) - 2))
  SEb1 = SEr / sqrt(sum({(y - (b0 + b1 * x))^2}))
  SEb0 = (SEr * (1/length(y)) * sum(x^2)) / sqrt(sum({(y - (b0 + b1 * x))^2}))
  print.df = data.frame(coef = round(c(b0,b1),3), SE = round(c(SEb0,SEb1),3))
  print.df$t.obs = round(print.df$coef / print.df$SE,3)
  print.df$p.value = round(2*pt(abs(print.df$t.obs), df = length(x) - 2, lower.tail = FALSE), 3)
  rownames(print.df) = c('Intercept', 'X')
  return(print.df)
}

victoria.lm(y=y, x=x)

summary(lm(y~x))
```

### Problem 2. 

Imagine that you've been urged by the teachers' union to show that higher teacher pay leads to better education outcomes.  Of course, you don't do advocacy research --- you are a seeker of truth --- but you decide to investigate this questions scientifically using data about SAT scores and other educational indicators at the state level.  For now we can pretend that this is the only available data (it comes from John Fox's website). [Read the data documentation](http://socserv.socsci.mcmaster.ca/jfox/Books/Applied-Regression-2E/datasets/States.pdf) and use the code below to load it

```{r echo=FALSE,message=FALSE,warnings=FALSE}
library(dplyr)
educ <- read.table("https://raw.githubusercontent.com/vcoxon/HW4/master/input/States.txt", header=TRUE)
# now clean up a bit
educ <- educ %>% rename(sat.verbal = satVerbal, sat.math = satMath, percent.taking = percentTaking, percent.no.hs = percentNoHS, teacher.pay = teacherPay) 
# not good to have state as a rowname
educ$state <- rownames(educ)
rownames(educ) <- NULL
educ <- tbl_df(educ)
```

(@) Make a scatter plot showing the relationship between average teacher pay and average SAT score at the state level.  To do this you might have to create a new variable.  And, overlay a regression line on the plot.
```{r}
library(ggplot2)
library(ggthemes)
 
ggplot(educ,aes(x=teacher.pay,y=sat.math+sat.verbal)) + geom_point() +
  geom_smooth(method=lm) + theme_few() + scale_x_continuous(expand=c(0,0))
```

(@) Fit a simple regression model to predict total SAT score based on teacher pay.
```{r}
educ = educ %>% mutate(sat.both = sat.math + sat.verbal)
model = lm(sat.both~teacher.pay,data = educ)
summary(model)
```
(@) Check whether the conditional mean of Y|X is a linear function of X.
*It is a reasonable assumption that Y is a linear funcion of X.  I don't see any obvious curvilinear trends in the scatterplot of the observations from the data.*

(@) Check whether the variance of Y|X is the same for any X. (Check for homo- or heteroskedasticity)  To check for heteroskedasticity, we need to plot residuals against predicted values (i.e., y-hats):
```{r}
plot(model$residuals~predict(model))
```
*It looks like the residuals are more evenly distributed the higher the combined score.  There is a distinct abscence of residuals towrads the lower score values.*

(@) Check whether the errors (and thus the Y|X) are independent of one another. (Are the errors iid?)  To check this assumption, we need to plot residuals against the regressor. It’s probably a good idea to use standardized residuals.
```{r}
plot(rstandard(model)~educ$teacher.pay, ylim = c(-2.5,2.5))
abline(h=0)
```
*This looks like a flipped version of the plot to check for heteroskedasticity.  The "hole" we saw in the earlier plot is here but on the higher end of teacher pay.  I wonder if there is a relationship?*

(@) Check whether the errors are normally distributed with mean zero. (Hint: histogram)
```{r}
hist(model$residuals)
```
*It looks nearly normal/normal enough.*

(@) Identify any outliers and quantify their influence and leverage. 
```{r}
plot(rstandard(model)~educ$teacher.pay,ylim = c(-2.5,2.5))
abline(h=0)
abline(h=2,lty=2)
abline(h=-2,lty=2)
#This places a dashed line at 2 and at -2
```
*Based on these standardized residuals, there doesn't appear to be any high iinfluence or high leverage outliers such that they pull at the line.  There is only one residual that is below the 2nd sd; this would be a normal occurance in a dataset of 51 observations(we could possibly expect at least 2).*
```{r}
summary(round(cooks.distance(model),2))
```
*Cook's Distance doesn't reveal any high leverage values either.*

(@) Explain the substantive conclusion that you would draw from the scatter plot and regression analysis. Be sure to interpret the coefficient in a complete sentence. 
```{r}
summary(model)
```
*This model predicts a decline of 4.8 points on a combined SAT score for every $1,000 increase in teacher pay.*

### Problem 3.

You don't necessarily believe these results, and think there might be more to the story. Thus, you decide to carry on to a multiple regression analysis using more variables.

(@) Using a figure or table, examine the pairwise correlations amongst potential model variables (go ahead and exclude the categorical indicators `state` and `region`. Comment on these results and how they will affect your model fitting. 
```{r}
library(knitr); library(dplyr)
kable(round(cor(educ %>% select(-state,-region)),3))
```

(@) Identify the optimal model(s) using all possible subsets and AIC/BIC.
```{r}
educ.subset = educ %>% dplyr::select(-state,-region,-sat.math,-sat.verbal)
model.list = list(m1 = lm(sat.both~population + percent.taking, data = educ.subset),
                  m2 = lm(sat.both~population + percent.no.hs, data = educ.subset),
                  m3 = lm(sat.both~population + teacher.pay, data = educ.subset),
                  m4 = lm(sat.both~percent.taking + percent.no.hs, data = educ.subset),
                  m5 = lm(sat.both~percent.taking + teacher.pay, data = educ.subset), 
                  m6 = lm(sat.both~percent.no.hs + teacher.pay, data = educ.subset),
                  m7 = lm(sat.both~population + percent.taking + percent.no.hs, data = educ.subset),
                  m8 = lm(sat.both~population + percent.taking + teacher.pay, data = educ.subset),
                  m9 = lm(sat.both~population + percent.no.hs + teacher.pay, data = educ.subset),
                  m10 = lm(sat.both~percent.taking + percent.no.hs + teacher.pay, data = educ.subset),
                  m11 = lm(sat.both~population + percent.taking + percent.no.hs + teacher.pay, data = educ.subset))

model.comps = data.frame(AIC = unlist(lapply(model.list,AIC)),BIC = unlist(lapply(model.list,BIC)),df = unlist(lapply(lapply(model.list,coef),length))-1)
model.comps
                  
```                  
(@) Identify the optimal model(s) using backward elimination and AIC/BIC.

(@) Identify the optimal model(s) using forward selection and AIC/BIC.

(@) Do the methods agree on the optimal model?  If not, why not?

(@) Assess whether your model is doing a good job of modeling the response (hint: think $Y$ vs. $\hat{Y}$  plot).

(@) Assess the relationship between each each predictor and the response (hint: marginal model plots). Is your model well-specified?

(@) Assess how much a given predictor $x_i$ can explain the response after the other predictors have been taken into account.

(@) Recommend a final model and provide your reasoning.

(@) Provide an interpretation (using sentences as you might in an academic journal) of your coefficient results.


### Problem 4.

Examine Angell’s data on the moral integration of U.S. cities (Angells is a data file in the car library). 

```{r message=FALSE,warnings=FALSE}
library(car)
data("Angell")
```

(@) Regress moral integration on heterogeneity and geographic mobility for the cities in dataset (multiple regression). 

(@) Report the finding of the results. Be sure to use a table to report $\beta_0$, $\beta_1$, and $\beta_2$ and statistics that allow for significance tests to be performed on these three coefficients. Write a paragraph to substantively explain the results of the model. 

### Report your process

You're encouraged to reflect on what was hard/easy, problems you solved, helpful tutorials you read, etc. Give credit to your sources, whether it's a blog post, a fellow student, an online tutorial, etc.

### Rubric

Minus: Didn't tackle at least 3 tasks. Or didn't make companion graphs. Didn't interpret anything but left it all to the "reader". Or more than one technical problem that is relatively easy to fix. It's hard to find the report in our repo.

Check: Completed, but not fully accurate and/or readable. Requires a bit of detective work on my part to see what you did

Check plus: Hits all the elements. No obvious mistakes. Pleasant to read. No heroic detective work required. Solid.




#### The command below is helpful for debugging, please don't change it

```{r echo=FALSE}
sessionInfo()
```









